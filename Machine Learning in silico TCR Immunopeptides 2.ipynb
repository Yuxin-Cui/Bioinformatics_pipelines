{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13d7a2f2-dbef-4a9c-b4b9-a415652168c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.10.3 anndata==0.10.9 umap==0.5.7 numpy==1.26.4 scipy==1.13.1 pandas==2.2.3 scikit-learn==1.1.2 statsmodels==0.14.4 pynndescent==0.5.13\n",
      "Linux 5.15.167.4-microsoft-standard-WSL2\n",
      "python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sc.logging.print_header()\n",
    "print(platform.system(), platform.release())\n",
    "print(\"python\", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a4f6dd3-1973-460c-88e6-57ac9937c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1787710, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "response_type\n",
       "not_tested    1364625\n",
       "negative       422907\n",
       "CD8               178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "hdf5_file_path = 'data/caner_mutant_peptides.h5'\n",
    "df = pd.read_hdf(hdf5_file_path, key='dataset_name')\n",
    "\n",
    "# Check the data structure\n",
    "print(df.shape)\n",
    "df['response_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2e38867-ce08-4b34-a357-4d7bdb226ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the predictors\n",
    "with open('predictors.txt', 'r') as f:\n",
    "    predictors = [line.strip() for line in f]\n",
    "\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e159f38-f444-4e78-8797-9ded2d88aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response_type\n",
       "negative    422907\n",
       "CD8            178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant columns (response_type and predictors)\n",
    "selected_columns = ['response_type', 'mutant_seq'] + predictors\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Filter out rows where 'response_type' is 'not_tested' for training data\n",
    "df_filtered = df_selected[df_selected['response_type'] != 'not_tested']\n",
    "# Update the categories of 'response_type'\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "df_filtered['response_type'] = df_filtered['response_type'].cat.remove_categories(['not_tested'])\n",
    "\n",
    "# Check the types of the target\n",
    "df_filtered['response_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900611f9-c398-45bd-a1c9-5391cf421d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the rows with 'not_tested' for later exploration\n",
    "df_not_tested = df_selected[df_selected['response_type'] == 'not_tested']\n",
    "df_not_tested.to_hdf('data/df_not_tested.h5', key='not_tested', mode='w', format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d47e1f-804a-4679-9bba-eb5d68380e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_type\n",
      "negative    422907\n",
      "CD8            178\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values for numeric columns with the mean\n",
    "numeric_columns = df_filtered.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_filtered[numeric_columns] = df_filtered[numeric_columns].fillna(df_filtered[numeric_columns].mean())\n",
    "\n",
    "# Impute missing values for categorical predictors with 'missing'\n",
    "categorical_columns = df_filtered.select_dtypes(include=['category', 'object']).columns\n",
    "for col in categorical_columns:\n",
    "    if df_filtered[col].dtype.name == 'category':\n",
    "        df_filtered[col] = df_filtered[col].cat.add_categories('missing')\n",
    "    df_filtered[col] = df_filtered[col].fillna('missing')\n",
    "\n",
    "# Ensure that 'response_type' doesn't contain the 'missing' category\n",
    "if df_filtered['response_type'].dtype.name == 'category':\n",
    "    df_filtered['response_type'] = df_filtered['response_type'].cat.remove_categories('missing')\n",
    "\n",
    "# Reset the index only if necessary, e.g., after row removal\n",
    "# df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "# Double-check the distribution of the target variable 'response_type'\n",
    "print(df_filtered['response_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cacc7b61-1b0f-4403-bc35-a229b7fdee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((338468, 26), (84617, 26))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for ML\n",
    "\n",
    "# Separate the 'mutant_seq' column\n",
    "mutant_seq_column = df_filtered['mutant_seq']\n",
    "\n",
    "# Drop 'mutant_seq' and 'response_type' columns from the predictors for model training\n",
    "X = df_filtered.drop(columns=['mutant_seq', 'response_type'])\n",
    "y = df_filtered['response_type']\n",
    "\n",
    "# Encode the target variable as binary\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  # Converts 'yes'/'no' to 1/0\n",
    "\n",
    "# Convert columns with non-numeric types to category dtype\n",
    "categorical_columns = ['bestWTMatchType_I', 'Zygosity', 'Clonality', \n",
    "                       'mutation_driver_statement_Intogen', 'gene_driver_Intogen']\n",
    "\n",
    "# Ensure the columns are of type 'category'\n",
    "for col in categorical_columns:\n",
    "    df_filtered[col] = df_filtered[col].astype('category')\n",
    "\n",
    "# 2. Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 4. Define preprocessors\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Standardize numeric features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# 5. Combine preprocessors in a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6. Apply preprocessing to the training set and test set\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "#\n",
    "X_train_processed.shape, X_test_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cba2bc20-c6a5-42eb-b24f-1f8b67752ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996454613139204\n",
      "ROC AUC Score: 0.5606001493226028\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.12      0.21        33\n",
      "           1       1.00      1.00      1.00     84584\n",
      "\n",
      "    accuracy                           1.00     84617\n",
      "   macro avg       0.90      0.56      0.61     84617\n",
      "weighted avg       1.00      1.00      1.00     84617\n",
      "\n",
      "Confusion Matrix:\n",
      "[[    4    29]\n",
      " [    1 84583]]\n"
     ]
    }
   ],
   "source": [
    "# Try to only predict \"negative\" (CD8) with high purity.\n",
    "    \n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\", \n",
    "    random_state=42,\n",
    "    scale_pos_weight=1.5,  # Adjust the weight for optimization\n",
    "    eval_metric=\"logloss\",\n",
    "    colsample_bytree=0.4,\n",
    ")\n",
    "\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Prediction metrics\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "# print(confusion_matrix(y_test, y_pred_adjusted))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7d6a1fc-b9bd-4d20-9a9e-003bc6072564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       response_type   mutant_seq  mutant_rank  mutant_rank_netMHCpan  \\\n",
      "248746      negative   GADGVGKSAL         0.08                  0.171   \n",
      "405655           CD8  YPAAVNTIVAI         0.80                  0.397   \n",
      "268852           CD8    TADFDITEL         0.06                  0.116   \n",
      "248744           CD8    GADGVGKSA         0.06                  1.307   \n",
      "320008           CD8    FVVPYMIYL         0.03                  0.123   \n",
      "\n",
      "        mutant_rank_PRIME  mut_Rank_Stab  TAP_score  mut_netchop_score_ct  \\\n",
      "248746               0.30          15.00      0.568              0.438231   \n",
      "405655               0.20           0.03     -0.160              0.940328   \n",
      "268852               0.05          19.00      0.648              0.974604   \n",
      "248744               0.30          25.00     -0.922              0.102754   \n",
      "320008               0.01           3.00      0.976              0.975419   \n",
      "\n",
      "        mut_binding_score  mut_is_binding_pos  ...  bestWTPeptideCount_I  \\\n",
      "248746           3.754320                True  ...                    32   \n",
      "405655          -0.168338               False  ...                    31   \n",
      "268852          -1.225484               False  ...                    84   \n",
      "248744           3.999764                True  ...                    32   \n",
      "320008          -0.035724               False  ...                   127   \n",
      "\n",
      "        bestWTMatchType_I  CSCAPE_score  Zygosity  Clonality       CCF  \\\n",
      "248746        PARTIAL_MUT      0.910278       LOH     clonal  0.770342   \n",
      "405655              EXACT      0.676691   HET|LOH     clonal  1.164148   \n",
      "268852               NONE      0.949296       HET  subclonal  0.075067   \n",
      "248744        PARTIAL_MUT      0.910278       LOH     clonal  0.770342   \n",
      "320008              EXACT      0.958919       HET     clonal  1.049645   \n",
      "\n",
      "        nb_same_mutation_Intogen  mutation_driver_statement_Intogen  \\\n",
      "248746                     159.0                       KNOWN DRIVER   \n",
      "405655                       0.0                            missing   \n",
      "268852                       0.0                            missing   \n",
      "248744                     159.0                       KNOWN DRIVER   \n",
      "320008                       0.0                            missing   \n",
      "\n",
      "        gene_driver_Intogen  seq_len  \n",
      "248746         TUMOR DRIVER       10  \n",
      "405655              missing       11  \n",
      "268852              missing        9  \n",
      "248744         TUMOR DRIVER        9  \n",
      "320008              missing        9  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the predicted neoantigen sequence for wet validation\n",
    "CD8_pred_index = np.where(y_pred == 0)[0]  # Indices where predictions are 0\n",
    "\n",
    "mutant_seq_pred = df_filtered.iloc[X_test.index[CD8_pred_index]]\n",
    "\n",
    "# 9. Optionally, print or inspect the results\n",
    "print(mutant_seq_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74ca3c2f-0aa1-4f5e-a9f4-bbcdcf94a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991691976789534\n",
      "ROC AUC Score: 0.814097121312434\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.64      0.06        33\n",
      "           1       1.00      0.99      1.00     84584\n",
      "\n",
      "    accuracy                           0.99     84617\n",
      "   macro avg       0.51      0.81      0.53     84617\n",
      "weighted avg       1.00      0.99      1.00     84617\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   21    12]\n",
      " [  691 83893]]\n"
     ]
    }
   ],
   "source": [
    "# Alternative strategy: Try to increase ture \"negative\" but decrease false \"negative\"\n",
    "# Increase the chance to identify more neoantigen hits but also more false \"negative\". \n",
    "\n",
    "# SMOTE option\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=42)  # Increase synthetic samples for class 0\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Train the XGBoost model with the resampled data\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train), \n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    #max_leaves=60\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "#\n",
    "threshold = 0.002  # Lower the threshold to favor predicting class 0\n",
    "y_pred_adjusted = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_adjusted)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c87870e-b4c8-4693-9188-4765387dbd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9866102556223927\n",
      "ROC AUC Score: 0.8418464771616669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.70      0.04        33\n",
      "           1       1.00      0.99      0.99     84584\n",
      "\n",
      "    accuracy                           0.99     84617\n",
      "   macro avg       0.51      0.84      0.52     84617\n",
      "weighted avg       1.00      0.99      0.99     84617\n",
      "\n",
      "[[   23    10]\n",
      " [ 1123 83461]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest algorithm\n",
    "# The outcome seems similar to the above. \n",
    "\n",
    "# Apply SMOTE to balance the class distribution in the training set\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Train the Random Forest model with the resampled data\n",
    "model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb793774-8b1a-4023-bf0f-d74fe67c857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"21.0.5\" 2024-10-15; OpenJDK Runtime Environment (build 21.0.5+11-Ubuntu-1ubuntu122.04); OpenJDK 64-Bit Server VM (build 21.0.5+11-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n",
      "  Starting server from /home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpcen_gi76\n",
      "  JVM stdout: /tmp/tmpcen_gi76/h2o_yc_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpcen_gi76/h2o_yc_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    }
   ],
   "source": [
    "# h2o platform (time consuming to run locally!)\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Initialize H2O\n",
    "h2o.init()\n",
    "\n",
    "# Convert the data to H2OFrame for AutoH2O\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data_h2o = h2o.H2OFrame(train_data)\n",
    "\n",
    "# Define target and features\n",
    "target = 'response_type'\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "# Train the AutoML model\n",
    "aml = H2OAutoML(max_models=20, seed=1, balance_classes=True)\n",
    "aml.train(x=features, y=target, training_frame=train_data_h2o)\n",
    "\n",
    "# View leaderboard and get the best model\n",
    "aml.leaderboard\n",
    "best_model = aml.leader\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_data_h2o = h2o.H2OFrame(X_test)\n",
    "predictions = best_model.predict(test_data_h2o)\n",
    "\n",
    "# View predictions (convert to dataframe)\n",
    "predictions_df = predictions.as_data_frame()\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7611c62-e1b9-4f0d-89c1-c2413d58814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996100074453124\n",
      "ROC AUC Score: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       1.00      1.00      1.00     84584\n",
      "\n",
      "    accuracy                           1.00     84617\n",
      "   macro avg       0.50      0.50      0.50     84617\n",
      "weighted avg       1.00      1.00      1.00     84617\n",
      "\n",
      "Evaluation with adjusted threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       1.00      1.00      1.00     84584\n",
      "\n",
      "    accuracy                           1.00     84617\n",
      "   macro avg       0.50      0.50      0.50     84617\n",
      "weighted avg       1.00      1.00      1.00     84617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yc/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Focal loss to deal with imbalanced data\n",
    "# Hyperparameter tuning  required could be tedious for optimization. \n",
    "\n",
    "# 1. Define Focal Loss for Binary Classification with Gradient and Hessian\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_inner(y_true, y_pred):\n",
    "        # Clip values to prevent log(0)\n",
    "        epsilon = 1e-8\n",
    "        y_true = np.clip(y_true, epsilon, 1 - epsilon)\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Cross-entropy loss\n",
    "        log_loss = -y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred)\n",
    "        \n",
    "        # Focal loss component\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        focal_loss = alpha * (1 - p_t) ** gamma * log_loss\n",
    "\n",
    "        # Compute gradient and hessian\n",
    "        grad = alpha * (1 - p_t) ** gamma * (y_pred - y_true) / (y_pred * (1 - y_pred))\n",
    "        hess = alpha * (1 - p_t) ** gamma * (1 - 2 * y_pred) / (y_pred * (1 - y_pred))\n",
    "\n",
    "        return grad, hess\n",
    "\n",
    "    return focal_loss_inner\n",
    "\n",
    "# 2. Calculate scale_pos_weight for Class Imbalance\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# 3. Initialize XGBoost model with focal loss as the custom objective function\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=focal_loss(gamma=2.0, alpha=0.25),  # Use custom focal loss\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle class imbalance\n",
    "    learning_rate=0.05,  # Slower learning rate to focus more on both classes\n",
    "    n_estimators=500,  # Increase number of trees to make up for slow learning\n",
    "    max_depth=6,  # Shallower trees to avoid overfitting\n",
    "    min_child_weight=2,  # Conservative splitting\n",
    "    subsample=0.8,  # Prevent overfitting by subsampling rows\n",
    "    colsample_bytree=0.8,  # Subsampling features\n",
    "    gamma=0.1,  # Control splits with small regularization\n",
    "    booster=\"dart\",  # Use dropout trees to improve generalization\n",
    "    eval_metric=\"auc\"  # Focus on AUC for class imbalance\n",
    ")\n",
    "\n",
    "# 4. Train the model on the original training data (without SMOTE)\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# 5. Make predictions on the test data\n",
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# 6. Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 7. Optional: Adjust the threshold for the positive class\n",
    "# Lowering the threshold increases recall for the minority class\n",
    "threshold = 0.3\n",
    "y_pred_adjusted = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# 8. Evaluate with the adjusted threshold\n",
    "print(\"Evaluation with adjusted threshold:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a4802-7a00-4fa4-b123-ab0caaa1582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lce (Good idea but yet to be validated)\n",
    "# ValueError to fix: Cannot cast object dtype to float64.\n",
    "# Time consuming.\n",
    "\n",
    "# Select all categorical columns in the dataset\n",
    "categorical_columns = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_columns)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_columns)\n",
    "\n",
    "# Ensure all data is numeric (after one-hot encoding, it should be)\n",
    "X_train_encoded = X_train_encoded.apply(pd.to_numeric, errors='coerce')\n",
    "X_test_encoded = X_test_encoded.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fit the model\n",
    "from lce import LCEClassifier\n",
    "clf = LCEClassifier(n_jobs=-1, random_state=0)\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions and compute accuracy\n",
    "y_pred_lce = clf.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_lce)\n",
    "print(\"Accuracy: {:.1f}%\".format(accuracy * 100))\n",
    "print(classification_report(y_test, y_pred_lce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e27bd-3e0e-48b0-ab07-84692856596b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
